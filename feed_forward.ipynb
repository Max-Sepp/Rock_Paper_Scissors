{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 19200  # 120x160\n",
    "num_classes = 3\n",
    "batch_size = 2\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Resize(120),\n",
    "    transforms.Grayscale(1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder('./rock_paper_scissors_data/train', transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = torchvision.datasets.ImageFolder('./rock_paper_scissors_data/test', transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['paper', 'rock', 'scissors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(FeedForwardNeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 3000)\n",
    "        self.linear2 = nn.Linear(3000, 3000)\n",
    "        self.linear3 = nn.Linear(3000, num_classes)\n",
    "        self.Relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.Relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.Relu(x)\n",
    "        x = self.linear3(x)\n",
    "        # no activation or softmax used \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeedForwardNeuralNet(input_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    # Test the model\n",
    "    # In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.reshape(-1, input_size).to(device)\n",
    "            labels = labels.to(device)\n",
    "            results = model(images)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(results.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        acc = n_correct / n_samples\n",
    "        print(f'Accuracy of the model: {acc * 100.0:.4f} %')\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, num_epochs, model):\n",
    "    total_steps = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # flatten images\n",
    "            images = images.reshape(-1, input_size).to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            results = model(images)\n",
    "            loss = criterion(results, labels)\n",
    "\n",
    "            # backwards and optimise\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1) % 25 == 0:\n",
    "                print(f'Epoch: {epoch+1} out of {num_epochs}, Step: {i+1} out of {total_steps}, Loss: {loss.item():.4f}') \n",
    "        test_model(model, test_loader)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(train_loader, 30, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba651ab6a70eeb6dc518b5c62efef8389255914b24900c2bd119f137816348a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
